{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\thaih\\\\Documents\\\\K22\\\\Nam_3\\\\HK1\\\\MachineLearning\\\\Project\\\\NeuralNetworkForClassification\\\\venv\\\\Scripts\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tarfile\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (50000, 3072), shape of train_Y: (50000,)\n",
      "Shape of test_X: (10000, 3072), shape of test_Y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    return data_dict\n",
    "\n",
    "def extract_cifar10(tar_gz_file, extract_to):\n",
    "    \"\"\" Extract the cifar-10 tar.gz file \"\"\"\n",
    "    with tarfile.open(tar_gz_file, 'r:gz') as tar:\n",
    "        tar.extractall(path=extract_to)\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    # List to store training data\n",
    "    train_X, train_Y = [], []\n",
    "    \n",
    "    # Load training batches (data_batch_1 to data_batch_5)\n",
    "    for i in range(1, 6):\n",
    "        batch_filename = os.path.join(data_dir, f'data_batch_{i}')\n",
    "        batch_data = unpickle(batch_filename)\n",
    "        train_X.append(batch_data[b'data'])\n",
    "        train_Y.append(batch_data[b'labels'])\n",
    "    \n",
    "    # Concatenate the training data into a single array\n",
    "    train_X = np.concatenate(train_X)\n",
    "    train_Y = np.concatenate(train_Y)\n",
    "    \n",
    "    # Load the test batch (test_batch)\n",
    "    test_batch_filename = os.path.join(data_dir, 'test_batch')\n",
    "    test_data = unpickle(test_batch_filename)\n",
    "    \n",
    "    test_X = test_data[b'data']\n",
    "    test_Y = test_data[b'labels']\n",
    "    \n",
    "    train_X = np.array(train_X)\n",
    "    train_Y = np.array(train_Y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_Y = np.array(test_Y)\n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y\n",
    "\n",
    "# Path to the tar.gz file\n",
    "tar_gz_file = 'cifar-10-python.tar.gz'\n",
    "\n",
    "# Check if the extracted folder exists, otherwise extract it\n",
    "extracted_folder = 'cifar-10-batches-py'\n",
    "if not os.path.exists(extracted_folder):\n",
    "    extract_cifar10(tar_gz_file, '.')\n",
    "\n",
    "# Load the data from the extracted folder\n",
    "train_X, train_Y, test_X, test_Y = load_cifar10_data(extracted_folder)\n",
    "\n",
    "print(f'Shape of train_X: {train_X.shape}, shape of train_Y: {train_Y.shape}')\n",
    "print(f'Shape of test_X: {test_X.shape}, shape of test_Y: {test_Y.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **data**: a 10000x3072 numpy array of uint8s. \n",
    "  - Each row of the array stores a 32x32 colour image. \n",
    "  - The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. \n",
    "  - The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "- **labels**: a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59  68 139 149 142 129 124 133 152 159 152   0  88 127 106 113 119 125\n",
      " 131 131 133 122  49 129 113 106 124 122 130 127 130 118]\n",
      "[ 43  98 145 131 144 137 139 136 163 158 148  18 120 126 101 109 109 127\n",
      " 124 132 123  25  83 130 112 105 130 115 131 126 142 120]\n",
      "[ 50 119 149 125 137 134 139 139 168 158  16  51 128 116 105 112 105 122\n",
      " 121 133 119  16 110 121 112 128 127 120 139 127 130 109]\n"
     ]
    }
   ],
   "source": [
    "# train_X[0] is a flattened array of size 3072\n",
    "image = train_X[0]\n",
    "\n",
    "# Reshaping it to a 32x32x3 image (32x32 pixels, 3 color channels)\n",
    "image_reshaped = image.reshape(32, 32, 3)\n",
    "\n",
    "red_channel_first_row = image_reshaped[0, :, 0]  # First row, Red channel\n",
    "green_channel_first_row = image_reshaped[0, :, 1]  # First row, Green channel\n",
    "blue_channel_first_row = image_reshaped[0, :, 2]  # First row, Blue channel\n",
    "\n",
    "# Print the first row of each channel\n",
    "print(red_channel_first_row)\n",
    "print(green_channel_first_row)\n",
    "print(blue_channel_first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3073)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_ones(X):\n",
    "    return np.hstack((np.ones((len(X), 1)), X))\n",
    "\n",
    "# Gọi hàm add_ones để tiền xử lý train_X\n",
    "train_Z = add_ones(train_X)\n",
    "train_Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode(y, num_classes):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "unique_classes = np.unique(train_Y)\n",
    "num_classes = len(unique_classes)\n",
    "train_Y_one_hot = one_hot_encode(train_Y, num_classes)\n",
    "\n",
    "train_Y_one_hot.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_final_project_env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
